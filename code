!pip install numpy
!pip install pandas
!pip install matplotlib
!pip install wordcloud
!pip install mlxtend
!pip install pyfpgrowth

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules
from mlxtend.preprocessing import TransactionEncoder
from wordcloud import WordCloud
import time
import pyfpgrowth

 #Load the dataset
dataset = pd.read_csv('/content/groceries - groceries.csv', header=None)
transactions =pd.DataFrame(dataset)
transactions

transactions = dataset.stack().groupby(level=0).apply(list).tolist()

# Preprocessing the dataset
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
groc_data = pd.DataFrame(te_ary, columns=te.columns_)

groc_data

# One-hot encode the transactions
try:
    te = TransactionEncoder()
    te_ary = te.fit(transactions).transform(transactions)
    df_encoded = pd.DataFrame(te_ary, columns=te.columns_)
except Exception as e:
    print(f"Error during one-hot encoding: {e}")
    print("Transaction format:", transactions[:5])

transactions = dataset.stack().groupby(level=0).apply(list).tolist()

# Preprocess the dataset
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_encoded = pd.DataFrame(te_ary, columns=te.columns_)

# Apply the Apriori algorithm
min_support = 0.01
frequent_itemsets_apriori = apriori(df_encoded, min_support=min_support, use_colnames=True)

# Generate association rules
#rules_apriori = association_rules(frequent_itemsets_apriori, metric="lift", min_threshold=1)

# Display the results
print(frequent_itemsets_apriori.head())
#print(rules_apriori.head())

# Find frequent itemsets using FP-Growth
min_support_count = int(min_support * len(transactions))
patterns_fp = pyfpgrowth.find_frequent_patterns(transactions, min_support_count)
rules_fp = pyfpgrowth.generate_association_rules(patterns_fp, 0.7)
# Display FP-Growth results
print("\nFP-Growth Patterns:\n", {k: patterns_fp[k] for k in list(patterns_fp)[:5]})
#print("\nFP-Growth Association Rules:\n", {k: rules_fp[k] for k in list(rules_fp)[:5]})

# Apriori Algorithm
start_time = time.time()
frequent_items_ap = apriori(groc_data, min_support=0.001, use_colnames=True)
apriori_time = time.time() - start_time
apriori_time

# FP-Growth Algorithm
start_time = time.time()
frequent_items_fp = fpgrowth(groc_data, min_support=0.001, use_colnames=True)
fp_growth_time = time.time() - start_time
fp_growth_time

# Most popular items using Apriori
most_pop_items_ap = frequent_items_ap.sort_values('support', ascending=False).head(15)
plt.figure(figsize=(10, 6))
most_pop_items_ap.plot.bar(x='itemsets', y='support', color='Green')
plt.xlabel('Item Name', fontsize=15)
plt.ylabel('Support Count', fontsize=15)
plt.title('Most Popular Items as per Apriori Support', fontsize=20)
plt.xticks(rotation=90, fontsize=10)
plt.yticks(fontsize=10)
plt.show()

# Wordcloud for Apriori
wordcloud_ap = WordCloud(background_color='black', width=1200, height=1200, max_words=121).generate(str(most_pop_items_ap['itemsets']))
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud_ap, interpolation='bilinear')
plt.axis('off')
plt.title('Most Popular Items (Apriori)', fontsize=20)
plt.show()

# Most popular items using FP-Growth
most_pop_items_fp = frequent_items_fp.sort_values('support', ascending=False).head(15)
plt.figure(figsize=(10, 6))
most_pop_items_fp.plot.bar(x='itemsets', y='support', color='Orange')
plt.xlabel('Item Name', fontsize=15)
plt.ylabel('Support Count', fontsize=15)
plt.title('Most Popular Items as per FP-Growth Support', fontsize=20)
plt.xticks(rotation=90, fontsize=10)
plt.yticks(fontsize=10)
plt.show()

# Wordcloud for FP-Growth
wordcloud_fp = WordCloud(background_color='lightgreen', width=1200, height=1200, max_words=121).generate(str(most_pop_items_fp['itemsets']))
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud_fp, interpolation='bilinear')
plt.axis('off')
plt.title('Most Popular Items (FP-Growth)', fontsize=20)
plt.show()

# Association Rules using Apriori
association_confi_ap = association_rules(frequent_items_ap, metric='confidence', min_threshold=0.4)
a_confi_top_ap = association_confi_ap.sort_values('confidence', ascending=False).head(10)
print("Top 10 Association Rules (Apriori):")
print(a_confi_top_ap)

# Association Rules using FP-Growth
association_confi_fp = association_rules(frequent_items_fp, metric='confidence', min_threshold=0.4)
a_confi_top_fp = association_confi_fp.sort_values('confidence', ascending=False).head(10)
print("Top 10 Association Rules (FP-Growth):")
print(a_confi_top_fp)

# Comparing the runtime and rules generated
print(f"Apriori Algorithm took {apriori_time:.4f} seconds.")
print(f"FP-Growth Algorithm took {fp_growth_time:.4f} seconds.")
print(f"Number of rules generated by Apriori: {len(association_confi_ap)}")
print(f"Number of rules generated by FP-Growth: {len(association_confi_fp)}")

# Conclusion
if apriori_time < fp_growth_time:
    print("Apriori algorithm is faster for this dataset.")
else:
    print("FP-Growth algorithm is faster for this dataset.")

if len(association_confi_ap) > len(association_confi_fp):
    print("Apriori algorithm generated more rules.")
else:
    print("FP-Growth algorithm generated more rules.")
